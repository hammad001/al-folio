---
---

@string{aps = {American Physical Society,}}

@article{ayyubi2019pgode,
    abbr={pgode.png},
    title={Progressive Growing of {Neural Ordinary Differential Equations}},
    author={Hammad A. Ayyubi and Yi Yao and Ajay Divakaran},
    journal={ICLR Workshop on Integration of Neural Networks and Differential Equations},
    year={2020},
    url={https://arxiv.org/abs/2003.03695},
    html={https://arxiv.org/abs/2003.03695},
    abstract={Neural Ordinary Differential Equations (NODEs) have proven to be a powerful modeling tool for approximating (interpolation) and forecasting (extrapolation) irregularly sampled time series data. However, their performance degrades substantially when applied to real-world data, especially long-term data with complex behaviors (e.g., long-term trend across years, mid-term seasonality across months, and short-term local variation across days). To address the modeling of such complex data with different behaviors at different frequencies (time spans), we propose a novel progressive learning paradigm of NODEs for long-term time series forecasting. Specifically, following the principle of curriculum learning, we gradually increase the complexity of data and network capacity as training progresses. Our experiments with both synthetic data and real traffic data (PeMS Bay Area traffic data) show that our training methodology consistently improves the performance of vanilla NODEs by over 64\%.} 
}

@article{ayyubi2019genrat,
    abbr={genrat.png},
    title={Generating Rationale in {Visual Question Answering}},
    author={Hammad A. Ayyubi* and Md. Mehrab Tanjim* and Julian McAuley and Garrison W. Cottrell},
    journal={arXiv:2004.02032},
    year={2019},
    url={https://arxiv.org/abs/2004.02032},
    html={https://arxiv.org/abs/2004.02032},
    abstract={Despite recent advances in Visual Question Answering (VQA), it remains a challenge to determine how much success can be attributed to sound reasoning and comprehension ability. We seek to investigate this question by proposing a new task of rationale generation. Essentially, we task a VQA model with generating rationales for the answers it predicts. We use data from the Visual Commonsense Reasoning (VCR) task, as it contains ground-truth rationales along with visual questions and answers. We first investigate commonsense understanding in one of the leading VCR models, ViLBERT, by generating rationales from pretrained weights using a state-of-the-art language model, GPT-2. Next, we seek to jointly train ViLBERT with GPT-2 in an end-to-end fashion with the dual task of predicting the answer in VQA and generating rationales. We show that this kind of training injects commonsense understanding in the VQA model through quantitative and qualitative evaluation metrics.}
}

@article{ayyubi2019ganspection,
    abbr={ganspection.png},
    title={GANspection},
    author={Hammad A. Ayyubi},
    year={2019},
    journal={arXiv:1910.09638},
    url={https://arxiv.org/abs/1910.09638},
    html={https://arxiv.org/abs/1910.09638},
    abstract={Generative Adversarial Networks (GANs) have been used extensively and quite successfully for unsupervised learning. As GANs don't approximate an explicit probability distribution, it's an interesting study to inspect the latent space representations learned by GANs. The current work seeks to push the boundaries of such inspection methods to further understand in more detail the manifold being learned by GANs. Various interpolation and extrapolation techniques along with vector arithmetic is used to understand the learned manifold. We show through experiments that GANs indeed learn a data probability distribution rather than memorize images/data. Further, we prove that GANs encode semantically relevant information in the learned probability distribution. The experiments have been performed on two publicly available datasets - Large Scale Scene Understanding (LSUN) and CelebA.}
}
